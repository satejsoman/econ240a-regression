{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECON240 (Regression), Fall 2021, Problem Set 5\n",
    "Satej Soman, satej@berkeley.edu\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Preliminaries: install packages, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (1.19.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/site-packages (0.12.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (4.61.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.8/site-packages (from matplotlib) (2021.5.30)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/site-packages (from statsmodels) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install numpy pandas matplotlib statsmodels scipy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import binom as Binomial\n",
    "from scipy.stats import multinomial as Multinomial\n",
    "from scipy.stats import norm as Normal\n",
    "from tqdm import trange\n",
    "\n",
    "sns.set_theme(context = \"notebook\", palette = \"bright\")\n",
    "plt.rc(\"axes.spines\", top = False, right = False)\n",
    "plt.rc(\"font\", **{'family':'sans-serif', 'sans-serif':'Helvetica Neue'})\n",
    "plt.rc('figure', dpi = 200)\n",
    "\n",
    "# index strings\n",
    "LATE    = \"LATE\"\n",
    "WALD_IV = \"WALD-IV\"\n",
    "MLE     = \"MLE\"\n",
    "EM      = \"EM\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset simulation\n",
    "\n",
    "## 1.1 Strata draws and encouragement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        ...,\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1]]),\n",
       " array([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "        1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "        1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "        1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 0, 1, 0, 1, 1, 0]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "πA = πN = πC = 1/3.0 \n",
    "N  = 1000 \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "A = Multinomial(1, [πA, πN, πC]).rvs(N)\n",
    "X = Binomial(1, 0.5).rvs(N)\n",
    "\n",
    "A, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = (A.T * [np.zeros(N), X, np.ones(N)]).sum(axis = 0)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observe that actual treatment is deterministic given a unit’s compliance-strata/type\n",
    "and encouragement. Comment.* \n",
    "\n",
    "Unlike an observed dataset, we know *a priori* to which compliance stratum each individual belongs. Given this information, and the encouragement, the exact outcome must be known deterministically.\n",
    "\n",
    "## 1.3 Potential outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y0_A100 = Normal(0, 1).rvs(N)\n",
    "Y0_A010 = Normal(1, 1).rvs(N)\n",
    "Y1_A010 = Normal(3, 1).rvs(N)\n",
    "Y1_A001 = Normal(4, 1).rvs(N)\n",
    "Y0      = np.where(A[:, 0], Y0_A100, Y0_A010)\n",
    "Y1      = np.where(A[:, 1], Y1_A010, Y1_A001)\n",
    "Y       = np.where(D      , Y1,      Y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 summary, average outcome difference vs late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>D</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>1.942039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500081</td>\n",
       "      <td>0.500054</td>\n",
       "      <td>2.022168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.649591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.884340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.664078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.915213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X            D            Y\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean      0.513000     0.486000     1.942039\n",
       "std       0.500081     0.500054     2.022168\n",
       "min       0.000000     0.000000    -2.649591\n",
       "25%       0.000000     0.000000     0.205145\n",
       "50%       1.000000     0.000000     1.884340\n",
       "75%       1.000000     1.000000     3.664078\n",
       "max       1.000000     1.000000     6.915213"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data = {\"X\": X, \"D\": D, \"Y\": Y})\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ΔȲ = 3.419944609586895, population LATE = 2.303092914373557\n"
     ]
    }
   ],
   "source": [
    "# average outcome difference \n",
    "ΔȲ       = (Y[D == 1].mean() - Y[D == 0].mean())\n",
    "pop_LATE = (Y[X == 1].mean() - Y[X == 0].mean()) / (D[X == 1].mean() - D[X == 0].mean())\n",
    "\n",
    "print(f\"ΔȲ = {ΔȲ}, population LATE = {pop_LATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive difference in means overestimates the true LATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# 2 Estimation\n",
    "\n",
    "## 2.1 WALD-IV estimate\n",
    "\n",
    "As is typical, we will implement the sample analog of the population LATE estimate by regressing Y on a constant and $D$, with $X$ as an instrument for $D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>standard error</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>0.293634</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.252484</td>\n",
       "      <td>0.334785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.374981</td>\n",
       "      <td>0.029313</td>\n",
       "      <td>0.317528</td>\n",
       "      <td>0.432435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coefficient  standard error    [0.025    0.975]\n",
       "intercept     0.293634        0.020996  0.252484  0.334785\n",
       "X             0.374981        0.029313  0.317528  0.432435"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, define an OLS (or copy-paste from the last pset)\n",
    "def OLS(Y, X, W = 1, add_constant = True, α = 0.05):\n",
    "    α = min(α, 1 - α)\n",
    "    N = len(Y)\n",
    "    regressors = list(X.columns)\n",
    "    if add_constant: \n",
    "        X, regressors = np.c_[np.ones(X.shape[0]), X], ['intercept'] + regressors\n",
    "    Γ_inv = np.linalg.inv((W * X.T) @ X)\n",
    "    β = Γ_inv @ (W * X.T).dot(Y) \n",
    "    u = Y - X.dot(β)\n",
    "    Ω = X.T.dot(X) * u.dot(u) / N\n",
    "    Λ = Γ_inv @ Ω @ Γ_inv.T\n",
    "    σ = np.sqrt(np.diag(Λ))\n",
    "    q = stats.norm.ppf(1 - α / 2)\n",
    "    output = pd.DataFrame(data = {\n",
    "        \"coefficient\"   : β, \n",
    "        \"standard error\": σ,\n",
    "        f\"[{α/2}\"       : β - q * σ, \n",
    "        f\"{1-α/2}]\"     : β + q * σ, \n",
    "}, index = regressors)\n",
    "    output.vcv = ''; output.vcv = Λ  # monkeypatch the var-cov matrix into the output while suppressing pandas UserError\n",
    "    return output\n",
    "\n",
    "# next, regress D on X: \n",
    "stage_1 = OLS(D, data[[\"X\"]], W = 1, add_constant = True)\n",
    "stage_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>standard error</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>0.822736</td>\n",
       "      <td>0.173530</td>\n",
       "      <td>0.482624</td>\n",
       "      <td>1.162848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_</th>\n",
       "      <td>2.303093</td>\n",
       "      <td>0.333142</td>\n",
       "      <td>1.650147</td>\n",
       "      <td>2.956039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coefficient  standard error    [0.025    0.975]\n",
       "intercept     0.822736        0.173530  0.482624  1.162848\n",
       "D_            2.303093        0.333142  1.650147  2.956039"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, regress Y on first stage fitted values:\n",
    "data[\"D_\"] = stage_1.loc[\"intercept\", \"coefficient\"] + X * stage_1.loc[\"X\", \"coefficient\"]\n",
    "stage_2 = OLS(Y, data[[\"D_\"]], W = 1, add_constant = True)\n",
    "β       = {WALD_IV: stage_2[\"coefficient\"].loc[\"D_\"]}\n",
    "stage_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the [0.025, 0.975] range of the standard error distribution does not contain the origin, we can reject the null of 0 LATE at the 5% significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 MLE-LATE estimate (complete data log-likelihood)\n",
    "\n",
    "As we have seen, encouraged compliers and non-encouraged compliers are comparable, so we can express the LATE in terms of the complete data log-likelihood parameters: $\\beta^{\\text{LATE}} = \\widehat{\\mu}_{C1} - \\widehat{\\mu}_{C0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1374515964061587"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C   = A[:, 1] == 1\n",
    "\n",
    "W1  = X[C] * D[C]\n",
    "μC1 = (W1 * Y[C]).sum() / W1.sum()\n",
    "\n",
    "W0  = (1 - X[C]) * (1 - D[C])\n",
    "μC0 = (W0 * Y[C]).sum() / W0.sum()\n",
    "\n",
    "β[MLE] = μC1 - μC0\n",
    "β[MLE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 MLE-LATE estimate (expectation maximization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running EM algorithm\n",
      "parameter difference after 1 iterations: 0.424\n",
      "parameter difference after 2 iterations: 0.101\n",
      "parameter difference after 3 iterations: 0.072\n",
      "parameter difference after 4 iterations: 0.044\n",
      "parameter difference after 5 iterations: 0.026\n",
      "parameter difference after 6 iterations: 0.014\n",
      "parameter difference after 7 iterations: 0.007\n",
      "parameter difference after 8 iterations: 0.004\n",
      "parameter difference after 9 iterations: 0.002\n",
      "parameter difference after 10 iterations: 0.001\n",
      "parameter difference after 11 iterations: 0.001\n",
      "parameter difference after 12 iterations: 0.001\n",
      "parameter difference after 13 iterations: 0.001\n",
      "parameter difference after 14 iterations: 0.001\n",
      "parameter difference after 15 iterations: 0.001\n",
      "parameter difference after 16 iterations: 0.001\n",
      "parameter difference after 17 iterations: 0.001\n",
      "parameter difference after 18 iterations: 0.001\n",
      "parameter difference after 19 iterations: 0.001\n",
      "parameter difference after 20 iterations: 0.001\n",
      "parameter difference after 21 iterations: 0.001\n",
      "parameter difference after 22 iterations: 0.001\n",
      "parameter difference after 23 iterations: 0.000\n",
      "parameter difference after 24 iterations: 0.000\n",
      "parameter difference after 25 iterations: 0.000\n",
      "parameter difference after 26 iterations: 0.000\n",
      "parameter difference after 27 iterations: 0.000\n",
      "parameter difference after 28 iterations: 0.000\n",
      "parameter difference after 29 iterations: 0.000\n",
      "parameter difference after 30 iterations: 0.000\n",
      "parameter difference after 31 iterations: 0.000\n",
      "parameter difference after 32 iterations: 0.000\n",
      "parameter difference after 33 iterations: 0.000\n",
      "parameter difference after 34 iterations: 0.000\n",
      "parameter difference after 35 iterations: 0.000\n",
      "parameter difference after 36 iterations: 0.000\n",
      "parameter difference after 37 iterations: 0.000\n",
      "parameter difference after 38 iterations: 0.000\n",
      "parameter difference after 39 iterations: 0.000\n",
      "parameter difference after 40 iterations: 0.000\n",
      "parameter difference after 41 iterations: 0.000\n",
      "parameter difference after 42 iterations: 0.000\n"
     ]
    }
   ],
   "source": [
    "converged, tolerance = False, 1e-6\n",
    "\n",
    "# initial weights \n",
    "μC0  = μC1  = μN0  = μA1  = 0\n",
    "σ2C0 = σ2C1 = σ2N0 = σ2A1 = 1\n",
    "π1   = π2   = π3   =        1/3.0\n",
    "\n",
    "ϕ = lambda y, m, s: Normal(m, s).pdf(y)\n",
    "\n",
    "def weights(w, y, m):\n",
    "    d = w.sum()\n",
    "    return (w * y).sum() / d, (w * (y - m)**2).sum() / d \n",
    "\n",
    "i = 0\n",
    "print(\"running EM algorithm\")\n",
    "while not converged:\n",
    "    Ã1 =\\\n",
    "        (1-X)*(1-D) * π1 * ϕ(Y, μN0, σ2N0) / (π1 * ϕ(Y, μN0, σ2N0) + π2 * ϕ(Y, μC0, σ2C0)) + \\\n",
    "           X *(1-D)\n",
    "    \n",
    "    Ã2 =\\\n",
    "        (1-X)*(1-D) * π2 * ϕ(Y, μC0, σ2C0) / (π1 * ϕ(Y, μN0, σ2N0) + π2 * ϕ(Y, μC0, σ2C0)) + \\\n",
    "           X *   D  * π2 * ϕ(Y, μC1, σ2C1) / (π2 * ϕ(Y, μC1, σ2C1) + π3 * ϕ(Y, μA1, σ2A1))\n",
    "\n",
    "    Ã3 =\\\n",
    "        (1-X)*  D   +\\\n",
    "           X *  D   * π2 * ϕ(Y, μA1, σ2A1) / (π2 * ϕ(Y, μC1, σ2C1) + π3 * ϕ(Y, μA1, σ2A1))\n",
    "    \n",
    "    π1, π2, π3 = Ã1.sum()/N, Ã2.sum()/N, Ã3.sum()/N\n",
    "\n",
    "    # single assignment for atomic updates:\n",
    "    μC0_prev = μC0\n",
    "    μC0, σ2C0, μC1, σ2C1, μN0, σ2N0, μA1, σ2A1 = chain(\n",
    "        weights(Ã2 * (1-D) * (1-X),           Y, μC0),\n",
    "        weights(Ã2 * D*X,                     Y, μC1),\n",
    "        weights(Ã1 * ((1-D)*(1-X) + (1-D)*X), Y, μN0),\n",
    "        weights(Ã3 * (D*(1-X) + D*X),         Y, μA1)\n",
    "    )\n",
    "\n",
    "    error = abs(μC0 - μC0_prev)\n",
    "    converged = error < tolerance\n",
    "    i += 1\n",
    "    print(f\"parameter difference after {i} iterations: {error:.3f}\")\n",
    "β[EM] = μC1 - μC0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 comparison of point estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         estimate\n",
      "WALD_IV  2.303093\n",
      "MLE      2.137452\n",
      "EM       2.616640\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(data = β.values(), index = β.keys()).rename(columns = {0: \"estimate\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# 3 Parametric Bootstrap\n",
    "\n",
    "## 3.1 generate bootstrap datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parameter difference after 42 iterations: 0.000: : 0it [54:39, ?it/s]\n",
      "parameter difference after 42 iterations: 0.000: : 0it [53:58, ?it/s]\n",
      "parameter difference after 42 iterations: 0.000: : 0it [53:28, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "B = 1000\n",
    "\n",
    "β_bs = []\n",
    "\n",
    "for b in range(B):\n",
    "    A_b       = Multinomial(1, [π1, π2, π3]).rvs(N)\n",
    "    D_b       = (A_b.T * [np.zeros(N), X, np.ones(N)]).sum(axis = 0)\n",
    "    Y0_A100_b = Normal(0, 1).rvs(N)\n",
    "    Y0_A010_b = Normal(1, 1).rvs(N)\n",
    "    Y1_A010_b = Normal(3, 1).rvs(N)\n",
    "    Y1_A001_b = Normal(4, 1).rvs(N)\n",
    "    Y0_b      = np.where(A_b[:, 0], Y0_A100_b, Y0_A010_b)\n",
    "    Y1_b      = np.where(A_b[:, 1], Y1_A010_b, Y1_A001_b)\n",
    "    Y_b       = np.where(D_b      , Y1_b,      Y0_b)\n",
    "    \n",
    "    converged = False\n",
    "\n",
    "    # initial weights \n",
    "    μC0_b  = μC1_b  = μN0_b  = μA1_b  = 0\n",
    "    σ2C0_b = σ2C1_b = σ2N0_b = σ2A1_b = 1\n",
    "    π1_b   = π2_b   = π3_b   =          1/3.0\n",
    "\n",
    "    while not converged:\n",
    "        Ã1_b =\\\n",
    "            (1-X)*(1-D_b) * π1_b * ϕ(Y_b, μN0_b, σ2N0_b) / (π1_b * ϕ(Y_b, μN0_b, σ2N0_b) + π2_b * ϕ(Y_b, μC0_b, σ2C0_b)) + \\\n",
    "            X    *(1-D_b)\n",
    "        \n",
    "        Ã2_b =\\\n",
    "            (1-X)*(1-D_b) * π2_b * ϕ(Y_b, μC0_b, σ2C0_b) / (π1_b * ϕ(Y_b, μN0_b, σ2N0_b) + π2_b * ϕ(Y_b, μC0_b, σ2C0_b)) + \\\n",
    "            X *   D_b     * π2_b * ϕ(Y_b, μC1_b, σ2C1_b) / (π2_b * ϕ(Y_b, μC1_b, σ2C1_b) + π3_b * ϕ(Y_b, μA1_b, σ2A1_b))\n",
    "\n",
    "        Ã3_b =\\\n",
    "            (1-X) * D_b +\\\n",
    "            X     * D_b * π2_b * ϕ(Y_b, μA1_b, σ2A1_b) / (π2_b * ϕ(Y_b, μC1_b, σ2C1_b) + π3 * ϕ(Y_b, μA1_b, σ2A1_b))\n",
    "        \n",
    "        π1_b, π2_b, π3_b = Ã1_b.sum()/N, Ã2_b.sum()/N, Ã3_b.sum()/N\n",
    "\n",
    "        # single assignment for atomic updates:\n",
    "        μC0_prev_b = μC0_b\n",
    "        μC0_b, σ2C0_b, μC1_b, σ2C1_b, μN0_b, σ2N0_b, μA1_b, σ2A1_b = chain(\n",
    "            weights(Ã2_b * (1-D_b) * (1-X),             Y_b, μC0_b),\n",
    "            weights(Ã2_b * D_b*X,                       Y_b, μC1_b),\n",
    "            weights(Ã1_b * ((1-D_b)*(1-X) + (1-D_b)*X), Y_b, μN0_b),\n",
    "            weights(Ã3_b * (D_b*(1-X) + D_b*X),         Y_b, μA1_b)\n",
    "        )\n",
    "\n",
    "        error = abs(μC0 - μC0_prev)\n",
    "        converged = error < tolerance\n",
    "\n",
    "    β_bs.append(μC1_b - μC0_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8477875829484876, 3.173102569476022)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β_bs_sorted = sorted(β_bs)\n",
    "CI = β_bs_sorted[int(0.025*B)], β_bs_sorted[int(0.975*B)]\n",
    "CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.07655102, 0.26792858, 0.45930614, 1.03343882, 1.83722457,\n",
       "        1.79894906, 2.67928583, 3.59789812, 4.05720426, 4.86099001,\n",
       "        4.51651041, 3.67444914, 3.06204095, 2.5644593 , 1.79894906,\n",
       "        1.18654087, 0.49758165, 0.11482654, 0.11482654, 0.07655102]),\n",
       " array([2.76105072, 2.78717708, 2.81330345, 2.83942982, 2.86555618,\n",
       "        2.89168255, 2.91780891, 2.94393528, 2.97006164, 2.99618801,\n",
       "        3.02231437, 3.04844074, 3.0745671 , 3.10069347, 3.12681983,\n",
       "        3.1529462 , 3.17907256, 3.20519893, 3.23132529, 3.25745166,\n",
       "        3.28357802]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(β_bs_sorted, bins = 20, density = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 varying compliance stratum size \n",
    "\n",
    "Since we can only observe exogenous variation in the complier stratrum, reducing the size of that stratum will give us similar estimates, but increase our standard errors."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
